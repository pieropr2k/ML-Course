{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Métodos No Supervisados - Parte 1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso:\n",
    "En una entidad bancaria existen varios canales de comunicación tales como: ATM, Oficinas, IVR, Banca por internet-Móvil, etc.\n",
    "Sin embargo, al realizar las comunicaciones de ofertas a los clientes de dicha entidad bancaria, el cliente recibe diversas ofertas de distintos canales sin saber si les da importancia o no, por lo que ya interviene un gasto por parte de la entidad, ya que, realiza alianzas estratégicas de campaña.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto: Se requiere identificar cuál sería el medio de comunicación preferido para los clientes y así enviarles ofertas, advertencia, recordatorios, etc. más direccionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7, 4)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracción Base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(\"data/01dataBaseMulti.txt\",delimiter='|')\n",
    "print(dataFrame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Número de filas: \" + str(dataFrame.shape[0]))\n",
    "print(\"Número de columnas: \" + str(dataFrame.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Metodología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3.1 Análisis Previo (objetivo)\n",
    "#### 3.2 Exploración (descriptivo, grafico barras,cajas)\n",
    "#### 3.3 Transformación (standarización,cajas)\n",
    "#### 3.4 Outliers (analisis y eliminación de outliers)\n",
    "#### 3.5 Dimensionamiento (PCA)\n",
    "#### 3.6 Modelamiento\n",
    "#### 3.7 Evaluación\n",
    "#### 3.8 Perfilamiento\n",
    "#### 3.9 Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables objetivo de estudio:\n",
    "channelName = ['trxAplus', 'trxBcaex', 'trxSalex', 'trxBm', 'trxBxi', 'trxIvr', 'trxSbt', 'trxVent',\n",
    "               'trxAtm','trxPostc', 'trxPostd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Análisis Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset ya se encuentra trabajado a nivel de cliente con sus respectivas variables, se consideraron filtros de criterios de autoasignados, distribución histórica de transacciones, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataFrame[channelName].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[channelName].hist(bins = 50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de cajas por variable en estudio:\n",
    "for columnName in channelName:\n",
    "    plt.title(columnName)  \n",
    "    plt.boxplot(dataFrame[columnName], 0, 'gD')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos la data original para poder usar las variables al final\n",
    "data_orig = dataFrame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Creamos el objeto para escalar\n",
    "# ------------------------------\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# ************\n",
    "# Lo aplicamos\n",
    "# ************\n",
    "for columnName in channelName:\n",
    "    dataFrame[columnName] = scaler.fit_transform(dataFrame[columnName].values.reshape(-1, 1))\n",
    "\n",
    "#for columnName in columName:\n",
    "#    dataFrame[columnName] = dataFrame[columnName]/dataFrame['trx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[channelName].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de intervalo del diagrama de cajas - Método de Rango Intercuartílico\n",
    "#def calculateNumOutliars(serie):\n",
    "#  Q01 = serie.quantile(0.25)\n",
    "#  Q03 = serie.quantile(0.75)\n",
    "#  IQR = Q03 - Q01\n",
    "#  a = (serie < (Q01 - 1.5 * IQR)) | (serie > (Q03 + 1.5 * IQR))\n",
    "#  numOutliars = a[a == True].shape[0]\n",
    "#  return numOutliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el método de Z-score (considerando se distribuye Normalmente) --- para grandes volúmenes de datos\n",
    "def calculateNumOutliars(serie):\n",
    "    mu = serie.mean()\n",
    "    desv = np.std(serie)\n",
    "    a = ((serie-mu)/desv < -3) | ((serie-mu)/desv > 3)\n",
    "    numOutliars = a[a == True].shape[0]\n",
    "    return a,numOutliars    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTotal = dataFrame.shape[0]\n",
    "for columnName in channelName:\n",
    "    a,numOutliars = calculateNumOutliars(dataFrame[columnName])\n",
    "    # Creamos nuevos campos para filtrar los Outliers \n",
    "    dataFrame['flg_'+columnName]=a\n",
    "    print('*'+columnName)\n",
    "    if numOutliars > 0:\n",
    "        print(\"Número de valores outliars: \" + str(numOutliars))\n",
    "        print(\"Porcentaje: \" + str(np.round(numOutliars * 100 / numTotal, 2)) + \"%\")\n",
    "    else:\n",
    "        print(\"****No hay Outliers\")    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************\n",
    "# Extrayendo los Outliers\n",
    "# ************************\n",
    "# Luego que cada variable tenga menos del 10% de Outlier, se filtra de manera Multivariada (este filtro podría ser\n",
    "# considerado como un segmento Heavy)\n",
    "\n",
    "dataFrame = dataFrame[(dataFrame['flg_trxAplus']==False)&\n",
    "                      (dataFrame['flg_trxBcaex']==False)&\n",
    "                      (dataFrame['flg_trxSalex']==False)&\n",
    "                      (dataFrame['flg_trxBm']==False)&\n",
    "                      (dataFrame['flg_trxBxi']==False)&\n",
    "                      (dataFrame['flg_trxIvr']==False)&\n",
    "                      (dataFrame['flg_trxSbt']==False)&\n",
    "                      (dataFrame['flg_trxVent']==False)&\n",
    "                      (dataFrame['flg_trxAtm']==False)&\n",
    "                      (dataFrame['flg_trxPostc']==False)&\n",
    "                      (dataFrame['flg_trxPostd']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acotamos la data original a la base sin outliers\n",
    "data_orig = data_orig.iloc[dataFrame.index,]\n",
    "data_orig = data_orig.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refrescamos los índices del Data frame final\n",
    "dataFrame = dataFrame.reset_index()\n",
    "print('Cantidad de Registros sin Outliers: '+str(dataFrame.shape[0]))\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Reducción de dimensión (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el máximo número de componentes (Nro variables = Nro máximo de componentes)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(dataFrame[channelName])\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pca.components_)):\n",
    "    print('% Var. explicada ('+str(i+1)+' componentes): ', np.cumsum(pca.explained_variance_ratio_)[i]*100)\n",
    "    \n",
    "plt.bar(range(1,len(pca.components_)+1),pca.explained_variance_ratio_, alpha=.2,color='0')\n",
    "plt.plot(range(1,len(pca.components_)+1),np.cumsum(pca.explained_variance_ratio_),alpha=0.4)\n",
    "plt.title(\"Varianza explicada y pareto\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el gráfico podemos observar que hay tendencia a que cada componente aporta información relevante, por lo que no existe alguna relación fuerte entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos la componente adecuada:\n",
    "pcaFin = PCA(n_components=11)\n",
    "pcaFin.fit(dataFrame[channelName])\n",
    "pd.DataFrame(pcaFin.components_,columns=channelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos nuestra evidencia en el gráfico de Pareto, donde: Para cada variable está asignado a cada Componente, Por tanto no existe reducción de dimensiones para nuestro estudio de canales de transacción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Modelamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances_argmin_min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando el número de clúster adecuado:\n",
    "X = dataFrame[channelName]\n",
    "\n",
    "numClus = range(1, 20)\n",
    "kmeans = [KMeans(n_clusters=i,max_iter=600, algorithm = 'auto') for i in numClus]\n",
    "kmeans\n",
    "score = [kmeans[i].fit(X).score(X)*-1 for i in range(len(kmeans))]\n",
    "score\n",
    "plt.plot(numClus,score)\n",
    "plt.xlabel('Número de Clúster')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Curva de Inflexión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos fijamos de los indicadores de clustering:\n",
    "\n",
    "ctdDf = int(0.1*dataFrame.shape[0])\n",
    "cluster = [kmeans[i].predict(X) for i in range(len(kmeans))]\n",
    "\n",
    "for i in range(1,11):    \n",
    "    print(str(i+1)+' clústeres:')\n",
    "    print('Inercia: '+str(kmeans[i].inertia_))\n",
    "    print('Silueta: '+str(metrics.silhouette_score(X, cluster[i], metric='euclidean',sample_size=ctdDf)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando los grupos en 2-D para tener alguna noción de como se agrupan, en esta ocasión probaremos distintos par de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "f1 = dataFrame['trxAtm'].values\n",
    "f2 = dataFrame['trxBm'].values\n",
    " \n",
    "#colores=['red','green','blue','cyan','yellow']\n",
    "colores=['red','green','blue']\n",
    "asignar=[]\n",
    "for row in cluster[1]:\n",
    "    asignar.append(colores[row])\n",
    "    \n",
    "plt.scatter(f1, f2, c=asignar, s=20)\n",
    "#plt.scatter(centroide[2][:, 0], centroide[2][:, 1], marker='*', c='yellow', s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "f1 = dataFrame['trxAtm'].values\n",
    "f2 = dataFrame['trxPostd'].values\n",
    " \n",
    "#colores=['red','green','blue','cyan','yellow']\n",
    "colores=['red','green','blue']\n",
    "asignar=[]\n",
    "for row in cluster[2]:\n",
    "    asignar.append(colores[row])\n",
    "    \n",
    "plt.scatter(f1, f2, c=asignar, s=20)\n",
    "#plt.scatter(centroide[2][:, 0], centroide[2][:, 1], marker='*', c='yellow', s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClus = [5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroide = [kmeans[i].cluster_centers_ for i in range(len(kmeans))]\n",
    "copy =  pd.DataFrame()\n",
    "\n",
    "for i in numClus:\n",
    "    # Distribución de los grupos por clúster:\n",
    "    copy['cluster'] = cluster[i-1]\n",
    "    cantidadGrupo =  pd.DataFrame()\n",
    "    cantidadGrupo['ctdCliente']=copy.groupby('cluster').size()\n",
    "    cantidadGrupo['pctCliente']=round(100*cantidadGrupo['ctdCliente']/cantidadGrupo['ctdCliente'].sum(),2)\n",
    "    \n",
    "    # gráfico de los grupos según su distribución:\n",
    "    plt.pie(cantidadGrupo['pctCliente'], labels=cantidadGrupo.index, autopct='%1.1f%%')\n",
    "    plt.title('Clúster '+str(i))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(cantidadGrupo)       \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numClusFinal = int(input('Ingrese el número de clúster: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fin = KMeans(n_clusters=numClusFinal,max_iter=600, algorithm = 'auto').fit(X)\n",
    "cluster = pd.DataFrame(kmeans_fin.predict(X))\n",
    "cluster.columns = ['cluster']\n",
    "\n",
    "centroide = kmeans_fin.cluster_centers_\n",
    "# Distribución de los grupos por clúster:\n",
    "cantidadGrupo =  pd.DataFrame()\n",
    "cantidadGrupo['ctdCliente']=cluster.groupby('cluster').size()\n",
    "cantidadGrupo['pctCliente']=round(100*cantidadGrupo['ctdCliente']/cantidadGrupo['ctdCliente'].sum(),2)\n",
    "\n",
    "# gráfico de los grupos según su distribución:\n",
    "plt.pie(cantidadGrupo['pctCliente'], labels=cantidadGrupo.index, autopct='%1.1f%%')\n",
    "plt.title('Clúster '+str(kmeans_fin))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(cantidadGrupo)       \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransp = pd.DataFrame(centroide,columns=channelName).T\n",
    "corr = dfTransp.corr()\n",
    "\n",
    "def plot_correlations(corr):\n",
    "    sns.set(style=\"white\")\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    mask = np.zeros_like(corr, dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(abs(corr), mask=mask, cmap=cmap, vmax=1, center=0,square=True) \n",
    "    \n",
    "plot_correlations(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisando los promedios en la data original\n",
    "data_orig['cluster'] = cluster\n",
    "data_orig.groupby('cluster')[channelName].mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Perfilamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTransp.plot(figsize=(20,20))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
